{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "# Specify the directory path where `assignemnt3.ipynb` exists.\n",
    "# For example, if you saved `assignment3.ipynb` in `/gdrive/My Drive/cs376/assignment3` directory,\n",
    "# then set root = '/gdrive/My Drive/CS376-2021F/HW3'\n",
    "root = '/gdrive/My Drive/CycleGAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL.Image import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets, utils\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import Discriminator, Generator\n",
    "from dataset import ImageDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.manual_seed(470)\n",
    "torch.cuda.manual_seed(470)\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "ROOT_DIR = root\n",
    "LOG_DIR = os.path.join(ROOT_DIR, \"logs\", now.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "LOG_ITER = 100\n",
    "CKPT_DIR = os.path.join(root, 'checkpoints')\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCHSIZE = 4\n",
    "LEARNING_RATE = 0.002\n",
    "MAX_EPOCH = 100\n",
    "\n",
    "LAMBDA = 10\n",
    "\n",
    "if not os.path.exists(CKPT_DIR):\n",
    "  os.makedirs(CKPT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_X, path_Y, transform = None):\n",
    "        self.path_X = glob.glob(os.path.join(path_X, '*.jpg'))\n",
    "        self.path_Y = glob.glob(os.path.join(path_Y, '*.jpg'))\n",
    "        shuffle(self.path_X)\n",
    "        shuffle(self.path_Y)\n",
    "        self.transform = transform\n",
    "        self.length = max(len(self.path_X), len(self.path_Y))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_X = Image.open(self.path_X[index % len(self.path_X)])\n",
    "        img_Y = Image.open(self.path_Y[index % len(self.path_Y)])\n",
    "        \n",
    "        if self.transform:\n",
    "            img_X = self.transform(img_X)\n",
    "            img_Y = self.transform(img_Y)\n",
    "        \n",
    "        return img_X, img_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Data Pipeline\n",
    "data_dir_X = os.path.join(ROOT_DIR, 'dataset', 'photo_jpg')\n",
    "data_dir_Y = os.path.join(ROOT_DIR, 'dataset', 'monet_jpg')\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#Helper Functions\n",
    "def imshow(img):\n",
    "    img = img.numpy()\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show():\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
    "        imshow(inputs[0])\n",
    "\n",
    "print(len(glob.glob(os.path.join(data_dir_X, '*.jpg'))))\n",
    "print(len(glob.glob(os.path.join(data_dir_Y, '*.jpg'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.ReflectionPad2d(1),\n",
    "                      nn.Conv2d(in_features, in_features, 3),\n",
    "                      nn.InstanceNorm2d(in_features)]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.features = self.create_layers()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "    def create_layers(self):\n",
    "        infos = ['c7s1-64', 'd128', 'd256', 'R256', 'R256', 'R256', 'R256',\n",
    "                 'R256', 'R256', 'R256', 'R256', 'R256', 'u128', 'u64', 'c7s1-3']\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in infos:\n",
    "            if x.startswith('c7s1-'):\n",
    "                layers += [nn.ReflectionPad2d(3),\n",
    "                           nn.Conv2d(in_channels, int(x[5:]), kernel_size=7),\n",
    "                           nn.InstanceNorm2d(int(x[5:])),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = int(x[5:])\n",
    "\n",
    "            elif x.startswith('d'):\n",
    "                layers += [nn.Conv2d(in_channels, int(x[1:]), kernel_size=3, stride=2, padding=1),\n",
    "                           nn.InstanceNorm2d(int(x[1:])),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = int(x[1:])\n",
    "\n",
    "            elif x.startswith('R'):\n",
    "                layers += [ResidualBlock(in_channels)]\n",
    "\n",
    "            elif x.startswith('u'):\n",
    "                layers += [nn.ConvTranspose2d(in_channels, int(x[1:]), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                           nn.InstanceNorm2d(int(x[1:])),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = int(x[1:])\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.features = self.create_layers()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    def create_layers(self):\n",
    "        infos = [64, 128, 256, 512]\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in infos:\n",
    "            if x == 64:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=4, stride=2),\n",
    "                           nn.InstanceNorm2d(x), \n",
    "                           nn.LeakyReLU(0.2, inplace=True)]\n",
    "                in_channels = x\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=4, stride=2), \n",
    "                           nn.LeakyReLU(0.2, inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.Conv2d(in_channels, 1, 4, padding=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(data_dir_X, data_dir_Y, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "Generator_XY = Generator().to(DEVICE)\n",
    "Discriminator_X = Discriminator().to(DEVICE)\n",
    "\n",
    "Generator_YX = Generator().to(DEVICE)\n",
    "Discriminator_Y = Discriminator().to(DEVICE)\n",
    "\n",
    "optimizer_generator = optim.Adam(itertools.chain(\n",
    "    Generator_XY.parameters(), Generator_YX.parameters()), lr=LEARNING_RATE)\n",
    "optimizer_discriminator_X = optim.Adam(\n",
    "    Discriminator_X.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_discriminator_Y = optim.Adam(\n",
    "    Discriminator_Y.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "img_size = torch.empty(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(LOG_DIR)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}\n",
    "\n",
    "iteration = 0\n",
    "ckpt_path = os.path.join(CKPT_DIR, 'lastest.pt')\n",
    "if os.path.exists(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    try:\n",
    "        optimizer_discriminator_X.load_state_dict(ckpt['discriminator_X'])\n",
    "        optimizer_discriminator_Y.load_state_dict(ckpt['discriminator_Y'])\n",
    "        optimizer_generator.load_state_dict(ckpt['generator'])\n",
    "    except RuntimeError as e:\n",
    "        print('wrong checkpoint')\n",
    "    else:\n",
    "        print('checkpoint is loaded!')\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    Generator_XY.train()\n",
    "    Generator_YX.train()\n",
    "    Discriminator_X.train()\n",
    "    Discriminator_Y.train()\n",
    "    for input_X, input_Y in train_dataloader:\n",
    "        iteration += 1\n",
    "        input_X = input_X.to(DEVICE)\n",
    "        input_Y = input_Y.to(DEVICE)\n",
    "\n",
    "        X_to_Y = Generator_XY(input_X)\n",
    "        Y_to_X = Generator_YX(input_Y)\n",
    "\n",
    "        # Train G\n",
    "        MSELoss = torch.nn.MSELoss().to(DEVICE)\n",
    "        result_XYY = Discriminator_Y(X_to_Y).detach()\n",
    "        result_YY = Discriminator_Y(input_Y).detach()\n",
    "        result_YXX = Discriminator_X(Y_to_X).detach()\n",
    "        result_XX = Discriminator_X(input_X).detach()\n",
    "        loss_GAN_G = (MSELoss(result_XYY, torch.ones_like(result_XYY).detach(\n",
    "        )) + MSELoss(result_YXX, torch.ones_like(result_YXX).detach())) / 2\n",
    "\n",
    "        # Cycle Consistency Loss\n",
    "        L1Norm = torch.nn.L1Loss().to(DEVICE)\n",
    "        loss_cyc = (L1Norm(Generator_YX(Y_to_X), input_X) +\n",
    "                    L1Norm(Generator_XY(Y_to_X), input_Y)) / 2 * LAMBDA\n",
    "\n",
    "        # Identity Loss\n",
    "        loss_identity = (L1Norm(X_to_Y, input_Y) +\n",
    "                            L1Norm(Y_to_X, input_X)) / 2 * LAMBDA\n",
    "\n",
    "        loss_G = loss_GAN_G + loss_cyc + loss_identity\n",
    "\n",
    "        optimizer_generator.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        loss_DX = MSELoss(result_XX, torch.ones_like(\n",
    "            result_XX).detach()) + MSELoss(result_YXX, torch.zeros_like(result_YXX.detach()))\n",
    "\n",
    "        optimizer_discriminator_X.zero_grad()\n",
    "        loss_DX.requires_grad = True\n",
    "        loss_DX.backward(retain_graph=True)\n",
    "        optimizer_discriminator_X.step()\n",
    "\n",
    "        loss_DY=MSELoss(result_YY, torch.ones_like(\n",
    "            result_YY).detach()) + MSELoss(result_XYY, torch.zeros_like(result_XYY).detach())\n",
    "        optimizer_discriminator_Y.zero_grad()\n",
    "        loss_DY.requires_grad = True\n",
    "        loss_DY.backward()\n",
    "        optimizer_discriminator_Y.step()\n",
    "\n",
    "        loss=loss_G.item() + loss_DX.item() + loss_DY.item()\n",
    "\n",
    "        if iteration % 20 == 0 and writer is not None:\n",
    "            writer.add_scalar('train_loss', loss, iteration)\n",
    "            print('[epoch: {}, iteration: {}] train loss : {:4f}'.format(\n",
    "                epoch+1, iteration, loss))\n",
    "\n",
    "        ckpt={'Discriminator_X': Discriminator_X.state_dict(),\n",
    "                'Discriminator_Y': Discriminator_Y.state_dict(),\n",
    "                'Generator_XY': Generator_XY.state_dict(),\n",
    "                'Generator_YX': Generator_YX.state_dict(),\n",
    "                'optim_discriminator_X': optimizer_discriminator_X.state_dict(),\n",
    "                'optim_discriminator_Y': optimizer_discriminator_Y.state_dict(),\n",
    "                'optim_generator': optimizer_generator.state_dict()}\n",
    "        torch.save(ckpt, ckpt_path)\n",
    "\n",
    "    print('[epoch: {}] train loss : {:4f}'.format(epoch+1, loss))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
